# This is a basic workflow to help you get started with Actions

name: Build_all

# Controls when the action will run. Triggers the workflow on push
# events but only for the master branch
on:
  push:
    branches: [ main ]

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains jobs called "bld_gnu_ompi", "bld_gnu_mpich" "bld_nvidia", "bld_intel", "bld_fftw3" and "bld_caliper"
  bld_gnu_ompi:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3

    # Runs a single command using the runners shell
    - name: Install requirements
      run: |
        sudo apt-get update
        sudo apt-get install -y gfortran openmpi-bin libopenmpi-dev

    # Runs a set of commands using the runners shell
    - name: Compile
      run: make BUILD=dev && make examples

  bld_gnu_mpich:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3

    # Runs a single command using the runners shell
    - name: Install requirements
      run: |
        sudo apt-get update
        sudo apt-get install -y gfortran mpich libmpich-dev

    # Runs a set of commands using the runners shell
    - name: Compile
      run: make BUILD=dev && make examples

###  bld_nvidia:
###    # The type of runner that the job will run on
###    runs-on: ubuntu-latest
###    env:
###      TMP: /opt/nvidia/hpc_sdk/Linux_x86_64/22.7/comm_libs/mpi/bin:/opt/nvidia/hpc_sdk/Linux_x86_64/22.7/compilers/bin
###
###    # Steps represent a sequence of tasks that will be executed as part of the job
###    steps:
###    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
###    - uses: actions/checkout@v3
###
###    # Add Nvidia HPC SDK
###    - name: setup repo
###      run: |
###        echo 'deb [trusted=yes] https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64 /' | sudo tee /etc/apt/sources.list.d/nvhpc.list
###    # Install dependencies
###    - name: install
###      run: |
###        sudo apt-get update  -y
###        sudo apt-get install -y nvhpc-22-7-cuda-multi
###
###    # Runs a set of commands using the runners shell
###    - name: CPU version
###      run: |
###        PATH=$TMP:$PATH make CMP=nvhpc BUILD=debug
###        PATH=$TMP:$PATH make examples
###
###    - name: GPU version
###      run: |
###        PATH=$TMP:$PATH make clean
###        PATH=$TMP:$PATH make CMP=nvhpc FFT=cufft PARAMOD=gpu CUFFT_PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/22.7/compilers

  bld_intel:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3

    # Add Intel OneApi
    - name: setup repo
      run: |
        sudo echo "deb [trusted=yes] https://apt.repos.intel.com/oneapi all main" | sudo tee /etc/apt/sources.list.d/oneAPI.list
    # Install dependencies
    - name: install
      run: |
        sudo apt-get update
        sudo apt-get install -y intel-oneapi-common-vars intel-oneapi-compiler-fortran intel-oneapi-mkl intel-oneapi-mkl-devel intel-oneapi-mpi intel-oneapi-mpi-devel

    # Runs a set of commands using the runners shell
    - name: Compile
      run: source /opt/intel/oneapi/setvars.sh && make CMP=intel BUILD=debug && make examples

    # Runs a set of commands using the runners shell
    - name: Compile
      run: source /opt/intel/oneapi/setvars.sh && make clean && make CMP=intel FFT=mkl BUILD=debug && make examples

  bld_fftw3:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3

    # Runs a single command using the runners shell
    - name: Install requirements
      run: |
        sudo apt-get update
        sudo apt-get install -y gfortran openmpi-bin libopenmpi-dev libfftw3-dev

    # Runs a set of commands using the runners shell
    - name: Regular FFTW3
      run: |
        make clean
        make BUILD=dev FFT=fftw3 FFTW3_PATH_INCLUDE=/usr/include FFTW3_PATH_LIB=/usr/lib/x86_64-linux-gnu
        make examples

    - name: New FFTW3
      run: |
        make clean
        make BUILD=dev FFT=fftw3_f03 FFTW3_PATH_INCLUDE=/usr/include FFTW3_PATH_LIB=/usr/lib/x86_64-linux-gnu
        make examples

  bld_caliper:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    - uses: actions/checkout@v3

    # Runs a single command using the runners shell
    - name: Install requirements
      run: |
        sudo apt-get update
        sudo apt-get install -y gfortran openmpi-bin libopenmpi-dev cmake gcc g++

    # Runs a set of commands using the runners shell
    - name: Compile caliper
      run: |
        wget --no-check-certificate https://github.com/LLNL/Caliper/archive/refs/tags/v2.8.0.tar.gz
        tar xzf v2.8.0.tar.gz && cd Caliper-2.8.0
        mkdir build && cd build
        cmake -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++ -DCMAKE_Fortran_COMPILER=gfortran -DCMAKE_INSTALL_PREFIX=../../Caliper-2.8.0_bld -DWITH_FORTRAN=yes -DWITH_MPI=yes ../
        make -j && make install
        cd ../../

    - name: Compile
      run: |
        make clean
        make BUILD=dev PROFILER=caliper CALIPER_PATH=./Caliper-2.8.0_bld
